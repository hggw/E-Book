<center><font size="10">redis简明文档</font></center>

***

# 1. redis概述

## （1）什么是redis？

​        [redis](https://redis.io) 是一个基于内存的高性能key-value数据库，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存，与memcached具有一定的相似度。
**redis优点**：性能好，支持保存多种数据结构，单个value的最大限制能达到1GB；
**redis缺点**：数据库容量受到物理内存的限制，不能用作海量数据的高性能读写；

## （2）redis支持的数据结构

| 数据类型 |                           典型应用                           |
| :------: | :----------------------------------------------------------: |
|  String  |  一般是存储简单的键值类型，如用户信息，登录信息，配置信息等  |
|   hash   |    适合存储两层信息的场景，如某个id的商品对应多种不同规格    |
|   list   | 可以使用左推、左拉、右推、右拉的方式作为集合存储，如存储某宝商铺里面的所有商品 |
|   set    |  无序且不重复，如保存一些不重复且对顺序没有要求的标签的名字  |
| sortset  |               有序且不重复，如排行榜之类的场景               |
| hyperlog |           一般用于统计使用，如统计页面PV/UV等数据            |
|   GEO    | 保存地理位置的信息，如使用地理位置时，并且需要计算，快速的场景 |

注：上述表格中，前5种为常见的数据结构，后2种使用不多。

## （3）为什么redis需要把所有数据放到内存中？

​       redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘，所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。**如果设置了最大使用的内存，则数据已有记录数达到内存限值后默认是不能继续插入新值。**

## （4）redis在linux和windows下的区别

​       目前，windows和linux都支持redis。但在早些时候，redis只能在linux上使用，原因在于redis在源码中很多地方写死了需要调用linux的Epoll方法来实现多路复用，windows没有Epoll方法。除此之外，windows也没有fork()函数。最终windows使用select来代替Epoll，fork也使用其他方法来代替，因此windows版本的redis始终是阉割版。
redis下载地址：[github下载](https://github.com/MSOpenTech/redis)、[官网下载](https://redis.io/download)



# 2. redis的线程模型

		我们通常在说redis是单线程的同时，往往会加上类似“高性能”等的修饰词，但是我们直观的感觉应该是多线程协同工作才能带来更高的性能，那么redis的线程模型到底是什么样的呢？
​        redis 的单线程主要是指 redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 redis 对外提供键值存储服务的主要流程，其内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。实际上，redis服务端虽然是单进程单线程的，但redis在处理持久化、异步删除、集群数据同步等是需要fork额外的线程去执行。redis 采用 IO 多路复用机制同时监听多个 socket，利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销，根据 socket 上的事件来选择对应的事件处理器进行处理。
![](pic\redis线程模型.PNG)

​           上述提到了两个关键的对象：文件事件处理器、IO多路复用。

## （1）文件事件处理器

​        redis基于Reactor模式（IO多路复用模式的一种）开发了网络事件处理器，这个处理器被称为文件事件处理器。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以redis才叫单线程模型。
<img src="C:\Users\Jacky_Hjq\Desktop\文件事件处理模型.PNG" style="zoom: 67%;"/>
​        在上图模型中，redis服务器用主线程执行I/O多路复用程序、文件事件分派器以及事件处理器。而且，尽管多个文件事件可能会并发出现，redis服务器是顺序处理各个文件事件的。redis服务器主线程的执行流程在redis.c的main函数中体现，而关于处理文件事件的主要的有这几行：

```c
int main(int argc,char **argv){
	...
    //建立各个事件处理器
	initServer();
	...
    //执行事件处理循环
	aeMain();
	...
    //关闭停止事件处理循环
	aeDeleteEventLoop(server.el);
    //退出
	return 0;
}
```

## （2）IO多路复用-Reactor模式

​       IO即为网络I/O，多路即为多个TCP连接，复用即为共用一个线程或者进程，模型最大的优势是系统开销小，不必创建也不必维护过多的线程或进程。IO多路复用又被称为事件驱动IO，最传统的多进程并发模型，是每进来一个新的I/O流会分配一个新的进程管理。IO多路复用下，单个线程通过记录跟踪每个I/O流(sock)的状态，来同时管理多个I/O流 。发明IO多路复用的原因，是尽量多的提高服务器的吞吐能力。
​       redis的I/O多路复用程序的所有功能是通过包装select、poll、epoll及kqueue等I/O多路复用函数库来实现的，每个I/O多路复用函数库在Redis源码中都对应一个单独的文件，比如ae_select.c、ae_poll.c、ae_epoll.c等。因为redis为每个I/O多路复用函数库都实现了相同的API，所以I/O多路复用程序的底层实现是可以互换的。简言之，**select/poll/kqueue/epoll这样的系统调用的功能是：你告知我一批套接字，当这些套接字的可读或可写事件发生时，我通知你这些事件信息**。以epoll为例：

<img src="pic\epoll模型.PNG" style="zoom: 50%;" />

​        那么为什么要有select, poll, epoll 等这么多的I/O多路复用的具体实现呢？实际上是由于出现的先后顺序，最早出现的是select，再是poll，到了现在，epoll在前两者的基础上已经实现得比较好，epoll没有链接数的限制，不仅线程安全，且能告诉你哪个socket有数据，免去轮询的消耗。epoll和kqueue类似，只是在不同操作系统中的实现。通过I/O多路复用函数库，我们解决了一个线程处理多个连接的问题，但整个Reactor模式的完整框架是怎样的呢？（了解详细[Reactor模式](http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf))
​		Reactor模式也称为异步阻塞IO（异步指socket为non-blocking，堵塞指select堵塞），为常见的四种IO模型之一，其他三种分别是：同步堵塞IO、同步非堵塞IO、异步（非堵塞）IO。目前的redis采用单线程的Reactor模式，通过主线程去响应处理IO事件，逐条执行命令，而其中Redis能够支撑高并发和快速响应的原因如下：1.redis是基于内存的，内存的读写速度非常快；2.redis是单线程的，省去了很多上下文切换线程的时间；3.redis使用多路复用技术，可以处理并发的连接。

![单线程的Reactor模型](pic\单线程的Reactor模型.PNG)

​      **上图单线程的Reactor模式整体流程是：**
 ① 服务器端的Reactor是一个线程对象，该线程会启动事件循环，并使用Selector来实现IO的多路复用。注册一个Acceptor事件处理器到Reactor中，Acceptor事件处理器所关注的事件是ACCEPT事件，这样Reactor会监听客户端向服务器端发起的连接请求事件(ACCEPT事件)。
 ② 客户端向服务器端发起一个连接请求，Reactor监听到了该ACCEPT事件的发生并将该ACCEPT事件派发给相应的Acceptor处理器来进行处理。Acceptor处理器通过accept()方法得到与这个客户端对应的连接(SocketChannel)，然后将该连接所关注的READ事件以及对应的READ事件处理器注册到Reactor中，这样一来Reactor就会监听该连接的READ事件了。或者当你需要向客户端发送数据时，就向Reactor注册该连接的WRITE事件和其处理器。
 ③ 当Reactor监听到有读或者写事件发生时，将相关的事件派发给对应的处理器进行处理。比如，读处理器会通过SocketChannel的read()方法读取数据，此时read()操作可以直接读取到数据，而不会堵塞与等待可读的数据到来。
 ④ 每当处理完所有就绪的感兴趣的I/O事件后，Reactor线程会再次执行select()阻塞等待新的事件就绪并将其分派给对应处理器进行处理。
​        **根据Redis单线程处理设计，后续的升级演进，猜测很可能是走单线程多Reactor模式**。一个典型的Redis最佳实践是，不推荐使用[big key](https://blog.csdn.net/shijinghan1126/article/details/108979820)，因为big key的操作会降低Reactor的响应速度。单线程多Reactor模式可以有效将连接动作和读写动作分离，提高吞吐量。



# 3. redis的内存模型

​        redis是一种内存型数据库，在了解redis的5种对象类型的用法和特点的基础上，进一步了解redis的内存模型，对redis的使用有很大帮助。本节主要介绍Redis的内存模型，包括Redis占用内存的情况及如何查询、不同的对象类型在内存中的编码方式、内存分配器(jemalloc)、简单动态字符串(SDS)、RedisObject等；然后在此基础上介绍几个Redis内存模型的应用。

## （1）redis内存统计

在说明redis的内存模型之前，我们先看一下redis的内存使用参数，在客户端通过redis-cli连接服务器后，通过info命令可以查看内存使用情况：

```shell
info memory
```

![redis内存使用](pic\redis内存使用.PNG)

返回结果中比较重要的几个说明如下：
1）**used_memory**：Redis分配器分配的内存总量（单位是字节），包括使用的虚拟内存（即swap）；Redis分配器后面会介绍。**used_memory_human**只是显示更友好。

2）**used_memory_rss**：Redis进程占据操作系统的内存（单位是字节），与top及ps命令看到的值是一致的；除了分配器分配的内存之外，used_memory_rss还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。

3）**mem_fragmentation_ratio**：内存碎片比率，该值是used_memory_rss / used_memory的比值。mem_fragmentation_ratio一般大于1，且该值越大，内存碎片比例越大。mem_fragmentation_ratio<1，说明Redis使用了虚拟内存，由于虚拟内存的媒介是磁盘，比内存速度要慢很多，当这种情况出现时，应该及时排查。
一般来说，**mem_fragmentation_ratio在1.03左右是比较健康的状态**（对于jemalloc来说）。

4）**mem_allocator**：Redis使用的内存分配器，在编译时指定；可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc。

## （2）redis内存划分

​        redis在内存中存储的内容主要是数据（键值对），通过前面的叙述可以知道，除了数据以外，redis的其他部分也会占用内存。redis的内存占用主要可以划分为以下几个部分：

### 1）数据

​        数据是最主要的部分；这部分占用的内存会统计在used_memory中。实际上，在redis内部，**每种数据类型可能有2种或更多的内部编码实现**；此外，redis在存储对象时，并不是直接将数据扔进内存，而是会对对象进行各种包装：如redisObject、SDS等。

### 2）进程运行本身所需的内存

​         redis主进程本身运行肯定需要占用内存，如代码、常量池等等（fork出的子线程也需要内存），这部分内存大约几兆，在大多数生产环境中与redis数据占用的内存相比可以忽略。这部分内存不是由jemalloc分配，因此**不会统计在used_memory中**。

### 3）缓冲内存

​        缓冲内存包括客户端缓冲区、复制积压缓冲区、AOF缓冲区等；其中，客户端缓冲存储客户端连接的输入输出缓冲；复制积压缓冲用于部分复制功能；AOF缓冲区用于在进行AOF重写时，保存最近的写入命令。在了解相应功能之前，不需要知道这些缓冲的细节；这部分内存由jemalloc分配，因此**会统计在used_memory中**。

### 4）内存碎片

​        内存碎片是Redis在分配、回收物理内存过程中产生的。例如，如果对数据的更改频繁，而且数据之间的大小相差很大，可能导致redis释放的空间在物理内存中并没有释放，但redis又无法有效利用，这就形成了内存碎片。内存碎片**不会统计在used_memory中**。内存碎片的产生与对数据进行的操作、数据的特点等都有关。此外，与使用的内存分配器也有关系：如果内存分配器设计合理，可以尽可能的减少内存碎片的产生。如果Redis服务器中的内存碎片已经很大，**可以通过安全重启的方式减小内存碎片**：因为重启之后，Redis重新从备份文件中读取数据，在内存中进行重排，为每个数据重新选择合适的内存单元，减小内存碎片。

## （3）redis存储数据的细节

​		redis在存储key和value的时候，并不是我们所想的是简单存储key-value，以 set hello world 为例，说明一下数据存储模型：
<img src="pic\redis数据存储模型.PNG" alt="redis数据存储模型" style="zoom: 50%;" />

(a）**dictEntry**：Redis是Key-Value数据库，因此对每个键值对都会有一个dictEntry，里面存储了指向Key和Value的指针；next指向下一个dictEntry，与本Key-Value无关。

(b）**Key**：”hello” 并不是直接以字符串存储，而是存储在SDS结构中。

(c）**redisObject**：Value(“world”)既不是直接以字符串存储，也不是像Key一样直接存储在SDS中，而是存储在redisObject中。实际上，不论Value是5种类型的哪一种，都是通过redisObject来存储的；而redisObject中的type字段指明了Value对象的类型，ptr字段则指向对象所在的地址。不过可以看出，字符串对象虽然经过了redisObject的包装，但仍然需要通过SDS存储。

(d）**jemalloc**：无论是DictEntry对象，还是redisObject、SDS对象，都需要内存分配器（如jemalloc）分配内存进行存储。以DictEntry对象为例，有3个指针组成，在64位机器下占24个字节，jemalloc会为它分配32字节大小的内存单元。

### 1）jemalloc

​        redis在编译时便会指定内存分配器；内存分配器可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc。jemalloc作为redis的默认内存分配器，在减小内存碎片方面做的相对比较好。jemalloc在64位系统中，将内存空间划分为小、大、巨大三个范围；每个范围内又划分了许多小的内存块单位；当redis存储数据时，会选择大小最合适的内存块进行存储。jemalloc划分的内存单元如下图所示：
<img src="pic\redis的jemolloc.PNG" alt="redis的jemolloc" style="zoom: 50%;" />

​         例如，如果需要存储大小为130字节的对象，jemalloc会将其放入160字节的内存单元中。

### 2）redisObject

​        redis常见的存储对象有5种类型。无论是哪种类型，redis都不会直接存储，而是通过redisObject对象进行存储。redisObject对象非常重要，redis对象的类型、内部编码、内存回收、共享对象等功能，都需要redisObject支持，下面将通过redisObject的结构来说明它是如何起作用的。

```c
typedef struct redisObject {
　　unsigned type:4;
　　unsigned encoding:4;
　　unsigned lru:REDIS_LRU_BITS;/* lru time (relative to server.lruclock) */
　　int refcount;
　　void *ptr;
} robj;
```

注：
-1-  **type**字段表示对象的类型，占4个比特；目前包括REDIS_STRING(字符串)、REDIS_LIST (列表)、REDIS_HASH(哈希)、REDIS_SET(集合)、REDIS_ZSET(有序集合)；

-2-  **encoding**表示对象的内部编码，占4个比特。对于redis支持的每种类型，都有至少两种内部编码，例如对于字符串，有int、embstr、raw三种编码。通过encoding属性，redis可以根据不同的使用场景来为对象设置不同的编码，大大提高了redis的灵活性和效率。以列表对象为例，有压缩列表和双端链表两种编码方式；如果列表中的元素较少，redis倾向于使用压缩列表进行存储，因为压缩列表占用内存更少，而且比双端链表可以更快载入；当列表对象元素较多时，压缩列表就会转化为更适合存储大量元素的双端链表；

-3-  **lru**记录的是对象最后一次被命令程序访问的时间，占据的比特数不同的版本有所不同（如4.0版本占24比特，2.6版本占22比特）；

-4-  **refcount**记录的是该对象被引用的次数，类型为整型，占4个字节。refcount的作用，主要在于对象的引用计数和内存回收。当创建新对象时，refcount初始化为1；当有新程序使用该对象时，refcount加1；当对象不再被一个新程序使用时，refcount减1；当refcount变为0时，对象占用的内存会被释放；

-5-  **共享对象**是Redis中被多次使用的对象(refcount>1)。Redis为了节省内存，当有一些对象重复出现时，新的程序不会创建新的对象，而是仍然使用原来的对象。这个被重复使用的对象，就是共享对象。目前共享对象仅支持整数值的字符串对象，之所以如此，实际上是对内存和CPU（时间）的平衡：共享对象虽然会降低内存消耗，但是判断两个对象是否相等却需要消耗额外的时间。对于整数值，判断操作复杂度为O(1)；对于普通字符串，判断复杂度为O(n)；而对于哈希、列表、集合和有序集合，判断的复杂度为O(n^2)；

-6-  **ptr**指针指向具体的数据，如前面的例子中，set hello world，ptr指向包含字符串world的SDS。ptr指针占据的字节数与系统有关，例如64位系统中占8个字节；

**总结：**redisObject的结构与对象类型、编码、内存回收、共享对象都有关系。在64位系统中，一个redisObject对象的大小为16字节：4bit+4bit+24bit+4Byte+8Byte=16Byte。

### 3）SDS

​        redis没有直接使用C字符串(即以空字符’\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。sds的结构如下：

```c
struct sdshdr {
    int len;
    int free;
    char buf[];
};
```

​        其中，buf表示字节数组，用来存储字符串；len表示buf已使用的长度，free表示buf未使用的长度。redis在存储对象时，一律使用SDS代替C字符串。例如set hello world命令，hello和world都是以SDS的形式存储的。而sadd myset member1 member2 member3命令，不论是键（”myset”），还是集合中的元素（”member1”、 ”member2”和”member3”），都是以SDS的形式存储。除了存储对象，SDS还用于存储各种缓冲区。只有在字符串不会改变的情况下，如打印日志时，才会使用C字符串。

## （4）redis的对象类型与内部编码

​        redis支持5种对象类型，而每种结构都有至少两种编码。这样做的好处在于：一方面接口与实现分离，当需要增加或改变内部编码时，用户使用不受影响，另一方面可以根据不同的应用场景切换内部编码，提高效率。redis各种对象类型支持的内部编码如下图所示(图中版本是Redis6.0，Redis后面版本中肯定又会增加内部编码，具体可以关注)：

<img src="pic\redis的内部编码.PNG" alt="redis的内部编码" style="zoom: 33%;" />
**redis这样的设计有两个好处：**
-1-  可以偷偷的改进内部编码，而对外的数据机构和命令没有影响，这样一旦开发出更优秀的内部编码，无需改动对外数据结构和命令；
-2-  多种内部编码的实现可以在不同的场景下发挥各自的又是。例如ziplist比较节省内存，但是列表元素比较多的情况下，性能会有所下降，这时redis会根据配置选项将列表类型的内部事项转换为linkedlist。

​        关于Redis内部编码的转换，都符合以下规律：**编码转换在Redis写入数据时完成，且转换过程不可逆，只能从小内存编码向大内存编码转换。**

## （5）应用举例

### 1）估算redis的内存使用量

​       要估算redis中的数据占据的内存大小，需要对redis的内存模型有比较全面的了解，包括前面介绍的hashtable、sds、redisobject、各种对象类型的编码方式等。下面以最简单的字符串类型来进行说明：
​       假设有90000个键值对，每个key的长度是7个字节，每个value的长度也是7个字节（且key和value都不是整数）。下面来估算这90000个键值对所占用的空间。在估算占据空间之前，首先可以判定字符串类型使用的编码方式：embstr。
​       90000个键值对占据的内存空间主要可以分为两部分：一部分是90000个dictEntry占据的空间；一部分是键值对所需要的bucket空间。每个**dictEntry**占据的空间包括：

-1-    一个**dictEntry**，24字节，jemalloc会分配32字节的内存块

-2-    一个**key**，7字节，所以SDS(key)需要7+9=16个字节，jemalloc会分配16字节的内存块

-3-    一个**redisObject**，16字节，jemalloc会分配16字节的内存块

-4-    一个**value**，7字节，所以SDS(value)需要7+9=16个字节，jemalloc会分配16字节的内存块

​        综上，一个dictEntry需要32+16+16+16=80个字节。

​        **bucket空间**：bucket数组的大小为大于90000的最小的2^n，是131072；每个bucket元素为8字节（因为64位系统中指针大小为8字节）。因此，可以估算出：
​        这90000个键值对占据的内存大小为：90000x80 + 131072x8 = 8248576字节。

### 2）优化内存占用

​        了解redis的内存模型，对优化redis内存占用有很大帮助。下面介绍几种优化场景。

​        **-1-  利用jemalloc特性进行优化**

​       上述的90000个键值便是一个例子。由于jemalloc分配内存时数值是不连续的，因此key/value字符串变化一个字节，可能会引起占用内存很大的变动；在设计时可以利用这一点。例如，如果key的长度如果是8个字节，则SDS为17字节，jemalloc分配32字节；此时将key长度缩减为7个字节，则SDS为16字节，jemalloc分配16字节；则每个key所占用的空间都可以缩小一半。

​        **-2-  使用整型/长整型**

​        如果是整型/长整型，Redis会使用int类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型。

​        **-3-  共享对象**

​        利用共享对象，可以减少对象的创建（同时减少了redisObject的创建），节省内存空间。目前redis中的共享对象只包括10000个整数（0-9999）；可以通过调整REDIS_SHARED_INTEGERS参数提高共享对象的个数；例如将REDIS_SHARED_INTEGERS调整到20000，则0-19999之间的对象都可以共享。考虑这样一种场景：论坛网站在redis中存储了每个帖子的浏览数，而这些浏览数绝大多数分布在0-20000之间，这时候通过适当增大REDIS_SHARED_INTEGERS参数，便可以利用共享对象节省内存空间。

​        **-4-  避免过度设计**

​        需要注意的是，不论是哪种优化场景，都要考虑内存空间与设计复杂度的权衡，而设计复杂度会影响到代码的复杂度、可维护性。如果数据量较小，那么为了节省内存而使得代码的开发、维护变得更加困难并不划算。还是以前面讲到的90000个键值对为例，实际上节省的内存空间只有几MB。但是如果数据量有几千万甚至上亿，考虑内存的优化就比较必要了。



# 4. redis持久化及内存淘汰策略

```
    有这样一个场景：一个朋友在windows下下载了redis，并且以redis.windows.conf配置文件启动，set了一个key，再get，可以拿到值。然后关闭redis服务，再开启，再get key，发现提示值没了，为何？ 
```

​        原因在于redis默认是不会把数据持久化到硬盘的，在没有配置持久化方案的情况下，可以在进入redis客户端执行命令**save**或**bgsave**可以生成dump.rdb文件进行数据保存（save是同步命令，bgsave是异步命令）。redis是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将redis中的数据以某种形式(数据或命令)从内存保存到硬盘。当下次redis重启时，利用持久化文件实现数据恢复。除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。**redis持久化分为RDB持久化和AOF持久化：前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存到硬盘（类似于MySQL的binlog）。**由于AOF持久化的实时性更好，即当进程意外退出时丢失的数据更少，因此AOF是目前主流的持久化方式，不过RDB持久化仍然有其用武之地。

## （1）RDB持久化

​        RDB持久化是将当前进程中的数据生成快照保存到硬盘(因此也称作快照持久化)，保存的文件后缀是rdb；当redis重新启动时，可以读取快照文件恢复数据。RDB持久化的触发分为**手动触发**和**自动触发**两种。手动触发前述已提及，在此不赘述。

### 1）自动触发

​       自动触发最常见的情况是在配置文件中通过save m n，指定当m秒内发生n次变化时，会触发bgsave。例如，查看redis的默认配置文件(Linux下为redis根目录下的redis.conf)，可以看到如下配置信息：
<img src="pic\rdb自动触发.PNG" alt="rdb自动触发" style="zoom:50%;" />
​        其中save 900 1的含义是：当时间到900秒时，如果redis数据发生了至少1次变化，则执行bgsave；save 300 10和save 60 10000同理。当三个save条件满足任意一个时，都会引起bgsave的调用。

**-1-  save m n的原理**，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的。**serverCron**是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查 save m n 配置的条件是否满足，如果满足就执行bgsave。**dirty**计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。**lastsave**时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。

**-2-  save m n执行日志**，下图是save m n触发bgsave执行时，服务器打印日志的情况：
![执行日志](pic\执行日志.png)

**-3-  其他自动触发机制**
a. 在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点；
b. 执行shutdown命令时，自动执行rdb持久化。

### 2）执行流程

<img src="pic\执行流程.PNG" alt="执行流程" style="zoom: 50%;" />

### 3）RDB文件

​        RDB文件是经过压缩的二进制文件，下面介绍关于RDB文件的一些细节。
​        **存储路径**：RDB文件的存储路径既可以在启动前配置，也可以通过命令动态设定。配置：dir配置指定目录，dbfilename指定文件名。默认是Redis根目录下的dump.rdb文件。动态设定：redis启动后也可以动态修改RDB存储路径，在磁盘损害或空间不足时非常有用；执行命令为config set dir {newdir}和config set dbfilename {newFileName}。如下所示(Windows环境)：
<img src="pic\windows下的路径设置.PNG" alt="windows下的路径设置" style="zoom:67%;" />
​        RDB文件内包含多个字段：1- REDIS：常量，保存着”REDIS”5个字符；2- db_version：RDB文件的版本号；3- SELECTDB 0 pairs：表示一个完整的数据库(0号数据库)；4- EOF：常量，标志RDB文件正文内容结束；5- check_sum：前面所有内容的校验和；Redis在载入RBD文件时，会计算前面的校验和并与check_sum值比较，判断文件是否损坏。
​        同时，redis默认采用LZF算法对RDB文件进行压缩。虽然压缩耗时，但是可以大大减小RDB文件的体积，因此压缩默认开启，可以通过命令关闭。

### 4）启动时加载

​        RDB文件的载入工作是在服务器启动时自动执行的，并没有专门的命令。但是由于AOF的优先级更高，因此当AOF开启时，Redis会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会在Redis服务器启动时检测RDB文件，并自动载入。**服务器载入RDB文件期间处于阻塞状态，直到载入完成为止**。

## （2）AOF持久化

​        RDB持久化是将进程数据写入文件，而AOF持久化(即Append Only File持久化)，则是将redis执行的每次写命令记录到单独的日志文件中（有点像MySQL的binlog）；当redis重启时再次执行AOF文件中的命令来恢复数据。与RDB相比，AOF的实时性更好，因此已成为主流的持久化方案。

### 1）开启AOF

​        redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：

```shell
appendonly yes
```

### 2）执行流程

​         由于需要记录Redis的每条写命令，因此AOF不需要触发，其执行流程主要包括：命令追加、文件写入与文件同步、文件重写。

**-1-  命令追加**，redis先将写命令追加到缓冲区，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为Redis负载的瓶颈。命令追加的格式是redis命令请求的协议格式，它是一种纯文本格式，具有兼容性好、可读性强、容易处理、操作简单避免二次开销等优点。

**-2-  文件写入与文件同步**，redis的数据并不是直接写入硬盘，而是会先写入缓冲区，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样就会有数据丢失的风险，AOF缓存区的同步文件策略由参数appendfsync控制，包含always、no及everysec。**everysec命令写入aof_buf后调用系统write操作，write完成后线程返回；fsync同步文件操作由专门的线程每秒调用一次。everysec是前述两种策略的折中，是性能和数据安全性的平衡，因此是Redis的默认配置，也是我们推荐的配置。**

**-3-  文件重写**，redis服务器执行的写命令越来越多，AOF文件也会越来越大；过大的AOF文件不仅会影响服务器的正常运行，也会导致数据恢复需要的时间过长。文件重写是指定期重写AOF文件，减小AOF文件的体积。需要注意的是，**AOF重写是把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取、写入操作!**

### 3）启动时加载

​        当AOF开启时，redis启动时会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会载入RDB文件恢复数据。当AOF开启，且AOF文件存在时，Redis启动日志：
![aof文件启动](pic\aof文件启动.PNG)

## （3）混合持久化

```
       重启 redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。
```

​		redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。AOF在重写(aof文件里可能有太多没用指令，所以aof会定期根据内存的最新数据生成aof文件)时将重写这一刻之前的内存rdb快照文件的内容和增量的 AOF修改内存数据的命令日志文件存在一起，都写入新的aof文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，原子的覆盖原有的AOF文件，完成新旧两个AOF文件的替换。AOF根据配置规则在后台自动重写，也可以人为执行命令bgrewriteaof重写AOF。 于是在 redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。

## （4）缓存淘汰策略

### 1）内存占用满的情况下

​		当 redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)，交换会让 redis 的性能急剧下降，对于访问量比较频繁的 redis 来说，这样龟速的存取效率基本上等于不可用。在生产环境中我们是不允许 redis 出现交换行为的，为了限制最大使用内存，redis 提供了配置参数 maxmemory 来限制内存超出期望大小。当实际内存超出 maxmemory 时，redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。

|      方式       |                             解释                             |
| :-------------: | :----------------------------------------------------------: |
|   noeviction    | 不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。 |
|  volatile-lru   | 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。 |
|  volatile-ttl   | 不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。 |
| volatile-random |   跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。   |
|   allkeys-lru   | 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。 |
| allkeys-random  |           跟上面一样，不过淘汰的策略是随机的 key。           |

​		volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。
<img src="pic\redis缓存淘汰策略.PNG" alt="redis缓存淘汰策略" style="zoom: 50%;" />

### 2）内存占用未满的情况下

​		LRU和LFU算法都是在redis内存占用满的情况下的淘汰策略，那么当内存没占满时在redis中过期的key是如何从内存中删除以达到优化内存占用的呢？ 
​		在redis中过期的key不会立刻从内存中删除，而是会同时以下面两种策略进行删除：
​		**惰性删除**：当key被访问时检查该key的过期时间，若已过期则删除；已过期未被访问的数据仍保持在内存中，消耗内存资源；
​		**定期删除**：每隔一段时间，随机检查设置了过期的key并删除已过期的key；维护定时器消耗CPU资源；
​		redis每10秒进行一次过期扫描：1. 随机取20个设置了过期策略的key；2. 检查20个key中过期时间中已过期的key并删除；3. 如果有超过25%的key已过期则重复第一步。这种循环随机操作会持续到过期key可能仅占全部key的25%以下时，并且为了保证不会出现循环过多的情况，默认扫描时间不会超过25ms。
​		**当redis中的key已过期未删除时，无论是AOF或RDB持久化模式都不会将过期key持久化到RDB文件或AOF文件中，可以保证重启服务时不会将过期key载入redis。**



# 5. redis的主从复制

​		主从复制，是指将一台redis服务器的数据，复制到其他的redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。默认情况下，每台redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。

## （1）redis角度谈主从复制与高可用的关系

​		在web服务器中，高可用是指服务器可以正常访问的时间，衡量的标准是在多长时间内可以提供正常服务（99.9%、99.99%、99.999% 等等）。但是在redis语境中，高可用的含义要更宽泛一些，除了保证提供正常服务(如主从分离、快速容灾技术)，还需要考虑数据容量的扩展、数据安全不会丢失等。
​		redis高可用的方案包括持久化、主从复制（及读写分离）、哨兵和集群。其中持久化侧重解决的是Redis数据的单机备份问题（从内存到硬盘的备份），而主从复制则侧重解决数据的多机热备。此外，主从复制还可以实现负载均衡和故障恢复。
​		主从复制的作用主要包括：
**-1-  数据冗余**：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
**-2-  故障恢复**：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
**-3-  负载均衡**：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
**-4-  高可用基石**：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。

## （2）使用主从复制

​		**主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。**
​		从节点开启主从复制，有3种方式：
​		**-1-  配置文件**
​		在从服务器的配置文件中加入：slaveof <masterip> <masterport>

​		**-2-  启动命令**
​		redis-server启动命令后加入 --slaveof <masterip> <masterport>

​		**-3-  客户端命令**
​		redis服务器启动后，直接通过客户端执行命令：slaveof <masterip> <masterport>，则该redis实例成为从节点。

​		上述3种方式是等效的，下面以客户端命令的方式为例，看一下当执行了slaveof后，Redis主节点和从节点的变化。通过slaveof <masterip> <masterport>命令建立主从复制关系以后，可以通过slaveof no one断开。需要注意的是，**从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。**

## （3）主从复制的实现原理

​		主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段。

### 1）连接建立阶段

​		该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。

**-1-  保存主节点信息**

​		从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。需要注意的是，**slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行**。

**-2-  建立socket连接**

​		从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功，则：
​		从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。
​		主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，**并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。**

**-3-  发送ping命令**

​		从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。从节点发送ping命令后，可能出现3种情况：
--1-- 返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。
--2-- 超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。
--3-- 返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。

**-4-  身份验证**

​		如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。

**-5-  发送从节点端口信息**

​		身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。

### 2）数据同步阶段

​		主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制。
​		需要注意的是，**在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端**。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。

### 3）命令传播阶段

​		数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。
​		需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。

## （4）全量复制与部分复制

​		在redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；在redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。

### 1）全量复制

​		全量复制是一个非常重型的操作，执行过程如下：
**-1-**  从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行部分复制；
**-2-**  主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令；
**-3-**  主节点的bgsave执行完成后，将RDB文件发送给从节点，**从节点首先清除自己的旧数据，然后载入接收的RDB文件**，将数据库状态更新至主节点执行bgsave时的数据库状态；
**-4-**  主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态；
**-5-**  如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态。

### 2）部分复制

​		由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。部分复制的实现，依赖于三个重要的概念：
**-1-**  **复制偏移量**。主节点和从节点分别维护一个复制偏移量（offset），代表的是**主节点向从节点传递的字节数**；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。
**-2-  复制积压缓冲区**。复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。
**-3-  服务器运行ID**。每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid。

## （5）心跳机制

​		在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。

### 1）主->从

​		每隔指定的时间，**主节点会向从节点发送PING命令**，这个PING命令的作用，主要是为了让从节点进行超时判断。PING发送的频率由repl-ping-slave-period参数控制，单位是秒，默认值是10s。

### 2）从->主

​		在命令传播阶段，**从节点会向主节点发送REPLCONF ACK命令**，频率是每秒1次；命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量。REPLCONF ACK命令的作用包括：实时监测主从节点网络状态、检测命令丢失及辅助保证从节点的数量和延迟。

## （6）应用中的问题

### 1）读写分离中的问题

​		在主从复制基础上实现的读写分离，可以实现redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）。在读负载较大的应用场景下，可以大大提高redis服务器的并发量。

**-1- 延迟与不一致问题**

​		由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。

**-2- 数据过期问题**

​		单机的情况下，redis有两种删除策略：
​		**惰性删除**：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。
​		**定期删除**：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。

​		在主从复制的情况下，为了主r从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过redis从节点读取数据时，很容易读取到已经过期的数据。redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回r给客户端。

**-3- 故障切换问题**

​		在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。

### 2）复制超时问题

​		主从节点复制超时是导致复制中断的最重要的原因之一，在复制连接建立过程中及之后，主从节点都有机制判断连接是否超时，其意义在于：
-1-  如果主节点判断连接超时，其会释放相应从节点的连接，从而释放各种资源，否则无效的从节点仍会占用主节点的各种资源（输出缓冲区、带宽、连接等）；此外连接超时的判断可以让主节点更准确的知道当前有效从节点的个数，有助于保证数据安全（配合前面讲到的min-slaves-to-write等参数）。
-2-  如果从节点判断连接超时，则可以及时重新建立连接，避免与主节点数据长期的不一致。
​		**主从复制超时判断的核心，在于repl-timeout参数**，该参数规定了超时时间的阈值（默认60s），对于主节点和从节点同时有效。与复制超时相关的一些实际情况：
​		**数据同步阶段**：在主从节点进行全量复制bgsave时，主节点需要首先fork子进程将当前数据保存到RDB文件中，然后再将RDB文件通过网络传输到从节点。如果RDB文件过大，主节点在fork子进程+保存RDB文件时耗时过多，可能会导致从节点长时间收不到数据而触发超时；此时从节点会重连主节点，然后再次全量复制，再次超时，再次重连……这是个悲伤的循环。为了避免这种情况的发生，除了注意Redis单机数据量不要过大，另一方面就是适当增大repl-timeout值，具体的大小可以根据bgsave耗时来调整。
​		**命令传播阶段**：如前所述，在该阶段主节点会向从节点发送PING命令，频率由repl-ping-slave-period控制；该参数应明显小于repl-timeout值(后者至少是前者的几倍)。否则，如果两个参数相等或接近，网络抖动导致个别PING命令丢失，此时恰巧主节点也没有向从节点发送数据，则从节点很容易判断超时。
​		**慢查询导致的阻塞**：如果主节点或从节点执行了一些慢查询（如keys *或者对大数据的hgetall等），导致服务器阻塞；阻塞期间无法响应复制连接中对方节点的请求，可能导致复制超时。

### 3）单机内存限制

​		在主从复制中，单机内存过大可能造成的影响：

**-1-  切主**：当主节点宕机时，一种常见的容灾策略是将其中一个从节点提升为主节点，并将其他从节点挂载到新的主节点上，此时这些从节点只能进行全量复制；如果Redis单机内存达到10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。

**-2-  从库扩容**：如果访问量突然增大，此时希望增加从节点分担读负载，如果数据量过大，从节点同步太慢，难以及时应对访问量的暴增。

**-3-  缓冲区溢出**：1和2都是从节点可以正常同步的情形（虽然慢），但是如果数据量过大，导致全量复制阶段主节点的复制缓冲区溢出，从而导致复制中断，则主从节点的数据同步会全量复制->复制缓冲区溢出导致复制中断->重连->全量复制->复制缓冲区溢出导致复制中断……的循环。

**-4-  超时**：如果数据量过大，全量复制阶段主节点fork+保存RDB文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制->超时导致复制中断->重连->全量复制->超时导致复制中断……的循环。

​		此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用50%-65%的内存，留下30%-45%的内存用于执行bgsave命令和创建复制缓冲区等。



# 6. 哨兵模式

​		前面提及的redis主从复制的作用有数据热备、负载均衡、故障恢复等，但**主从复制存在的一个问题是故障恢复无法自动化**。本节将要介绍的**哨兵，基于redis主从复制，主要作用便是解决主节点故障恢复的自动化问题，进一步提高系统的高可用性**。

## （1）作用及架构

​		从宏观角度来看，redis实现高可用相关的技术主要包括：持久化、复制、哨兵和集群。Redis Sentinel，即Redis哨兵，在Redis 2.8版本开始引入。**哨兵的核心功能是主节点的自动故障转移。**官方描述的作用为：

**-1-  监控**：哨兵会不断地检查主节点和从节点是否运作正常。

**-2-  自动故障转移**：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。

**-3-  配置提供者**：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。

**-4-  通知**：哨兵可以将故障转移的结果发送给客户端。

​		其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。

​		典型的哨兵架构如下图所示：
<img src="\pic\哨兵架构.PNG" alt="哨兵架构" style="zoom: 67%;" />

​		哨兵架构由两部分组成，哨兵节点和数据节点：1. **哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的redis节点，不存储数据；**2. **主节点和从节点都是数据节点。**

## （2）案例部署

​		部署一个简单的哨兵系统，包含1个主节点、2个从节点和3个哨兵节点。为了方便，所有这些节点都部署在一台机器上（192.168.92.128），使用端口号区分。

### 1）部署主从节点

​		**哨兵系统中的主从节点，与普通的主从节点配置是一样的**，并不需要做任何额外配置。下面分别是主节点（port=6379）和2个从节点（port=6380/6381）的配置文件，配置都比较简单。

```shell
#redis-6379.conf
port 6379
daemonize yes
logfile "6379.log"
dbfilename "dump-6379.rdb"
 
#redis-6380.conf
port 6380
daemonize yes
logfile "6380.log"
dbfilename "dump-6380.rdb"
slaveof 192.168.92.128 6379
 
#redis-6381.conf
port 6381
daemonize yes
logfile "6381.log"
dbfilename "dump-6381.rdb"
slaveof 192.168.92.128 6379
```

​		配置完成后，依次启动主节点和从节点：

```shell
redis-server redis-6379.conf
redis-server redis-6380.conf
redis-server redis-6381.conf
```

​		节点启动后，连接主节点查看主从状态是否正常：
![主从节点启动](\pic\主从节点启动.PNG)

### 2）部署哨兵节点

​		哨兵节点本质上是特殊的Redis节点。3个哨兵节点的配置几乎是完全一样的，主要区别在于端口号的不同（26379/26380/26381），下面以26379节点为例介绍节点的配置和启动方式。

```shell
#sentinel-26379.conf
port 26379
daemonize yes
logfile "26379.log"
sentinel monitor mymaster 192.168.92.128 6379 2
```

​		其中，sentinel monitor mymaster 192.168.92.128 6379 2 配置的含义是：该哨兵节点监控192.168.92.128:6379这个主节点，该主节点的名称是mymaster，**最后的2的含义与主节点的故障判定有关：至少需要2个哨兵节点同意，才能判定主节点故障并进行故障转移。**启动哨兵节点：

```shell
redis-sentinel sentinel-26379.conf
```

​		按照上述方式配置和启动之后，整个哨兵系统就启动完毕了，此时如果查看哨兵节点的配置文件，会发现一些变化，以26379为例：
![哨兵模式启动完成后信息](\pic\哨兵模式启动完成后信息.PNG)

### 3）模拟自动故障转移

​		哨兵的监控和自动故障转移功能是哨兵的主要作用之二，模拟故障转移采用杀死主节点的方式来模拟主节点故障。首先，先使用ps aux|grep 6379查找出主节点的进程号，然后将主节点kill掉：

```shell
ps aux | grep 6379

kill -9 xxxx         # xxxx代表查询处理的主节点进程号
```

​		如果此时立即在哨兵节点中使用info Sentinel命令查看，会发现主节点还没有切换过来，因为哨兵发现主节点故障并转移，需要一段时间。过会再次查看发现主节点已经切换成6380节点。
![故障转移](\pic\故障转移.PNG)

​		但是可以发现，哨兵节点认为新的主节点仍然有2个从节点，这是因为哨兵在将6380切换成主节点的同时，将6379节点置为其从节点；虽然6379从节点已经挂掉，但是由于哨兵并不会对从节点进行客观下线。因此认为该从节点一直存在。**当6379节点重新启动后，会自动变成6380节点的从节点**。

### 4）配置提供及通知

​		**配置提供**：客户端可以通过哨兵节点+masterName获取主节点信息，在这里哨兵起到的作用就是配置提供者。**注意，哨兵只是配置提供者，而不是代理**。二者的区别在于：如果是配置提供者，客户端在通过哨兵获得主节点信息后，会直接建立到主节点的连接，后续的请求(如set/get)会直接发向主节点；如果是代理，客户端的每一次请求都会发向哨兵，哨兵再通过主节点处理请求。

​		**通知**：哨兵节点在故障转移完成后，会将新的主节点信息发送给客户端，以便客户端及时切换主节点。

## （3）哨兵节点主要命令

​		哨兵系统要实现故障发现、故障转移等各种功能，离不开哨兵节点之间的通信，而通信的很大一部分是通过哨兵节点支持的命令来实现的。

|                   命令                    |                        作用                        |
| :---------------------------------------: | :------------------------------------------------: |
|               info sentinel               |           获取监控的所有主节点的基本信息           |
|             sentinel masters              |           获取监控的所有主节点的详细信息           |
|         sentinel master mymaster          |         获取监控的主节点mymaster的详细信息         |
|         sentinel slaves mymaster          |     获取监控的主节点mymaster的从节点的详细信息     |
|        sentinel sentinels mymaster        |    获取监控的主节点mymaster的哨兵节点的详细信息    |
| sentinel get-master-addr-by-name mymaster |         获取监控的主节点mymaster的地址信息         |
|      sentinel is-master-down-by-addr      |   询问主节点是否下线，从而对是否客观下线做出判断   |
|        sentinel monitor mymaster 2        | 与哨兵节点配置文件中的sentinel monitor功能完全一样 |
|        sentinel remove mymaster 2         |      取消当前哨兵节点对主节点mymaster2的监控       |
|        sentinel failover mymaster         | **强制对**mymaster执行故障转移，即便主节点运行完好 |

## （4）若干重要概念

### 1）定时任务

​		每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。

### 2）主观下线

​		在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线。

### 3）客观下线

​		哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线，**客观下线是主节点才有的概念**。

### 4）选举领导者哨兵节点

​		当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。

### 5）故障转移

​		选举出的领导者哨兵，开始进行故障转移操作：
**-1-  从从节点中选择主节点**，选择的原则是首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。

**-2-  更新主从状态**，通过slaveof no one命令，让选出来的从节点成为主节点，并通过slaveof命令让其他节点成为其从节点。

**-3-  离线的主将变从**，将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。

## （5）实践要点

**-1-**  哨兵节点的数量应不止一个，一方面增加哨兵节点的冗余，避免哨兵本身成为高可用的瓶颈；另一方面减少对下线的误判。此外，这些不同的哨兵节点应部署在不同的物理机上。

**-2-**  哨兵节点的数量应该是奇数，便于哨兵通过投票做出“决策”：领导者选举的决策、客观下线的决策等。

**-3-**  各个哨兵节点的配置应一致，包括硬件、参数等；此外，所有节点都应该使用ntp或类似服务，保证时间准确、一致。

**-4-**  哨兵的配置提供者和通知客户端功能，需要客户端的支持才能实现，如前文所说的Jedis；如果开发者使用的库未提供相应支持，则可能需要开发者自己实现。

**-5-**  当哨兵系统中的节点在docker（或其他可能进行端口映射的软件）中部署时，应特别注意端口映射可能会导致哨兵系统无法正常工作，因为哨兵的工作基于与其他节点的通信，而docker的端口映射可能导致哨兵无法连接到其他节点。例如，哨兵之间互相发现，依赖于它们对外宣称的IP和port，如果某个哨兵A部署在做了端口映射的docker中，那么其他哨兵使用A宣称的port无法连接到A。



# 7. 集群模式

​		集群，即Redis Cluster，是Redis 3.0开始引入的分布式存储方案。集群由多个节点(Node)组成，redis的数据分布在这些节点中。**集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制**。

## （1）集群作用及方案设计

​		**集群的作用，可以归纳为两点：**

​		**-1-  数据分区**：数据分区(或称数据分片)是集群最核心的功能。
​		集群将数据分散到多个节点，一方面突破了redis单机内存大小的限制，存储容量大大增加；另一方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。redis单机内存大小受限问题，在持久化和主从复制时都有提及。例如，如果单机内存太大，bgsave和bgrewriteaof的fork操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出……。

​		**-2-  高可用**：集群支持主从复制和主节点的自动故障转移（与哨兵类似），当任一节点发生故障时，集群仍然可以对外提供服务。

​		**设计集群方案时，至少要考虑以下因素：**

**-1-  高可用要求**：根据故障转移的原理，至少需要3个主节点才能完成故障转移，且3个主节点不应在同一台物理机上；每个主节点至少需要1个从节点，且主从节点不应在一台物理机上；因此高可用集群至少包含6个节点。

**-2-  数据量和访问量**：估算应用需要的数据量和总访问量(考虑业务发展，留有冗余)，结合每个主节点的容量和能承受的访问量(可以通过benchmark得到较准确估计)，计算需要的主节点数量。

**-3-  节点数量限制**：redis官方给出的节点数量限制为1000，主要是考虑节点间通信带来的消耗。在实际应用中应尽量避免大集群；如果节点数量不足以满足应用对redis数据量和访问量的要求，可以考虑：a. 业务分割，大集群分为多个小集群；b. 减少不必要的数据；(3)调整数据过期策略等。

**-4-  适度冗余**：Redis可以在不影响集群服务的情况下增加节点，因此节点数量适当冗余即可，不用太大。

## （2）集群的搭建

​		集群的搭建有两种方式：（1）手动执行redis命令，一步步完成搭建；（2）使用Ruby脚本搭建。二者搭建的原理是一样的，只是Ruby脚本将redis命令进行了打包封装。在实际应用中推荐使用脚本方式，简单快捷不容易出错。下面使用手动执行命令的方式搭建一个3主3从的集群，方便起见：所有节点在同一台服务器上，以端口号进行区分，配置从简。3个主节点端口号：7000/7001/7002，对应的从节点端口号：8000/8001/8002。
​		集群的搭建可以分为四步：
**-1-  启动节点**：将节点以集群模式启动，此时节点是独立的，并没有建立联系；
**-2-  节点握手**：让独立的节点连成一个网络；
**-3-  分配槽**：将16384个槽分配给主节点；
**-4-  指定主从关系**：为从节点指定主节点。
​		实际上，前三步完成后集群便可以对外提供服务；但指定从节点后，集群才能够提供真正高可用的服务。

### 1）启动节点

​		集群节点的启动仍然是使用redis-server命令，但需要使用集群模式启动。下面是7000节点的配置文件：

```shell
#redis-7000.conf
port 7000
cluster-enabled yes
cluster-config-file "node-7000.conf"
logfile "log-7000.log"
dbfilename "dump-7000.rdb"
daemonize yes
```

​		其中的cluster-enabled和cluster-config-file是与集群相关的配置。**cluster-enabled yes**：redis实例可以分为单机模式(standalone)和集群模式(cluster)，cluster-enabled yes可以启动集群模式。
<img src="\pic\redis集群启动.PNG" alt="redis集群启动" style="zoom:67%;" />

​		**cluster-config-file**：该参数指定了集群配置文件的位置。每个节点在运行过程中，会维护一份集群配置文件；每当集群信息发生变化时（如增减节点），集群内所有节点会将最新信息更新到该配置文件；当节点重启后，会重新读取该配置文件，获取集群信息，可以方便的重新加入到集群中。也就是说，**当redis节点以集群模式启动时，会首先寻找是否有集群配置文件，如果有则使用文件中的配置启动，如果没有，则初始化配置并将配置保存到文件中。集群配置文件由redis节点维护，不需要人工修改。**
​		编辑好配置文件后，使用redis-server命令启动该节点：

```shell
redis-server redis-7000.conf
```

​		节点启动以后，通过cluster nodes命令可以查看节点的情况，其中返回值第一项表示节点id，由40个16进制字符串组成，节点id与主从复制中提到的runId不同：redis每次启动runId都会重新创建，但是节点id只在集群初始化时创建一次，然后保存到集群配置文件中，以后节点重新启动时会直接在集群配置文件中读取。
![集群启动的id](\pic\集群启动的id.PNG)		其他节点使用相同办法启动，不再赘述。需要特别注意，**在启动节点阶段，节点是没有主从关系的**，因此从节点不需要加slaveof配置。

### 2）节点握手

​		节点启动以后是相互独立的，并不知道其他节点存在，需要进行节点握手，将独立的节点组成一个网络。节点握手使用cluster meet {ip} {port}命令实现，例如在7000节点中执行cluster meet 192.168.72.128 7001，可以完成7000节点和7001节点的握手，ip使用的是局域网ip而不是localhost或127.0.0.1，是为了其他机器上的节点或客户端也可以访问。使用命令与所有节点进行握手：

```shell
cluster meet 192.168.72.128 7001
cluster meet 192.168.72.128 7002
cluster meet 192.168.72.128 8000
cluster meet 192.168.72.128 8001
cluster meet 192.168.72.128 8002
```

​		执行完上述命令后，再使用cluster nodes命令可以看到7000节点已经感知到了所有其他节点：
![节点握手完成](\pic\节点握手完成.PNG)

### 3）分配槽

​		在redis集群中，借助槽实现数据分区。**集群有16384个槽，槽是数据管理和迁移的基本单位。当数据库中的16384个槽都分配了节点时，集群处于上线状态（ok）；如果有任意一个槽没有分配节点，则集群处于下线状态（fail）。**这一特性与哈希分区有关。cluster info命令可以查看集群状态，分配槽之前状态为fail：
<img src="\pic\未分配槽位.PNG" alt="未分配槽位" style="zoom:67%;" />

​		分配槽使用cluster addslots命令，执行下面的命令将槽（编号0-16383）全部分配完毕：

```shell
redis-cli -p 7000 cluster addslots {0..5461}
redis-cli -p 7001 cluster addslots {5462..10922}
redis-cli -p 7002 cluster addslots {10923..16383}
```

​		执行完上述命令后，此时再查看集群状态，可以看到集群已上线：
<img src="\pic\已分配槽位.PNG" alt="已分配槽位" style="zoom:67%;" />

### 4）指定主从关系

​		**集群中指定主从关系不再使用slaveof命令，而是使用cluster replicate命令**。参数使用节点id。通过cluster nodes获得几个主节点的节点id后，执行下面的命令为每个从节点指定主节点：

```shell
redis-cli -p 8000 cluster replicate be816eba968bc16c884b963d768c945e86ac51ae
redis-cli -p 8001 cluster replicate 788b361563acb175ce8232569347812a12f1fdb4
redis-cli -p 8002 cluster replicate a26f1624a3da3e5197dde267de683d61bb2dcbf1
```

​		此时执行cluster nodes查看各个节点的状态，可以看到主从关系已经建立：
<img src="\pic\建立主从关系.PNG" alt="建立主从关系" style="zoom: 50%;" />

​		到这里，集群搭建完毕。

## （3）集群基本原理

​		**集群最核心的功能是数据分区**。

### 1）数据分区方案

​		数据分区有顺序分区、哈希分区等，其中哈希分区由于其天然的随机性，使用广泛。**集群的分区方案便是哈希分区的一种**。哈希分区的基本思路是：对数据的特征值（如key）进行哈希，然后根据哈希值决定数据落在哪个节点。常见的哈希分区包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。
​		衡量数据分区方法好坏的标准有很多，其中**比较重要的两个因素是：a. 数据分布是否均匀;b. 增加或删减节点对数据分布的影响**。由于哈希的随机性，哈希分区基本可以保证数据分布均匀；因此在比较哈希分区方案时，重点要看增减节点对数据分布的影响。

​		**-1-  哈希取余分区**
​		哈希取余分区思路非常简单：计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。该方案最大的问题是，当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。

​		**-2-  一致性哈希分区**
​		一致性哈希算法将整个哈希值空间组织成一个虚拟的圆环，如下图所示，范围为0-2^32-1；对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。
<img src="\pic\一致性哈希.PNG" alt="一致性哈希" style="zoom: 50%;" />

​		与哈希取余分区相比，一致性哈希分区将增减节点的影响限制在相邻节点。以上图为例，如果在node1和node2之间增加node5，则只有node2中的一部分数据会迁移到node5；如果去掉node2，则原node2中的数据只会迁移到node4中，只有node4会受影响。**一致性哈希分区的主要问题在于，当节点数量较少时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡**。还是以上图为例，如果去掉node2，node4中的数据由总数据的1/4左右变为1/2左右，与其他节点相比负载过高。
​		为了解决一致性哈希带来的问题，引入带虚拟节点的一致性哈希分区。redis集群使用的便是该方案，其中的**虚拟节点称为槽（slot）**。**槽是介于数据和实际节点之间的虚拟概念，每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据**。**引入槽以后，数据的映射关系由数据hash->实际节点，变成了数据hash->槽->实际节点。**槽的数量一般远小于2^32，远大于实际节点的数量，**在redis集群中，槽的数量为16384**。
<img src="\pic\数据与槽的映射关系.PNG" alt="数据与槽的映射关系" style="zoom: 50%;" />

​		redis对数据的特征值（一般是key）计算哈希值，使用的算法是CRC16，先计算该数据落在哪个槽，再根据槽与节点的映射关系明确存储的节点。

### 2）节点通信机制

​		**在集群中，没有数据节点与非数据节点之分：所有的节点都存储数据，也都参与集群状态的维护**。为此，集群中的每个节点，都提供了两个TCP端口：

-1-  普通端口：即我们在前面指定的端口(7000等)。普通端口主要用于为客户端提供服务（与单机节点类似）；但在节点间数据迁移时也会使用。

-2-  集群端口：**端口号是普通端口+10000（10000是固定值，无法改变）**，如7000节点的集群端口为17000。集群端口只用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。

​		节点间的通信协议分为几种：单对单、广播、Gossip协议等。重点区分一下广播和Gossip协议，广播的集群收敛速度快，但是消耗的cpu和带宽等较大；Gossip协议不同，虽然收敛速度慢，但是消耗较低、去中心化及容错性高。
​		集群中的节点采用固定频率（每秒10次）的定时任务进行通信相关的工作：判断是否需要发送消息及消息类型、确定接收节点、发送消息等。如果集群状态发生了变化，如增减节点、槽状态变更，通过节点间的通信，所有节点会很快得知整个集群的状态，使集群收敛。

### 3）数据结构

​		节点需要专门的数据结构来存储集群的状态。所谓集群的状态，是一个比较大的概念，包括：集群是否处于上线状态、集群中有哪些节点、节点是否可达、节点的主从状态、槽的分布……。节点为了存储集群状态而提供的数据结构中，最关键的是clusterNode和clusterState结构：前者记录了一个节点的状态，后者记录了集群作为一个整体的状态。
​		**clusterNode数据结构**：

```c
typedef struct clusterNode {
    //节点创建时间
    mstime_t ctime;
 
    //节点id
    char name[REDIS_CLUSTER_NAMELEN];
 
    //节点的ip和端口号
    char ip[REDIS_IP_STR_LEN];
    int port;
 
    //节点标识：整型，每个bit都代表了不同状态，如节点的主从状态、是否在线、是否在握手等
    int flags;
 
    //配置纪元：故障转移时起作用，类似于哨兵的配置纪元
    uint64_t configEpoch;
 
    //槽在该节点中的分布：占用16384/8个字节，16384个比特；每个比特对应一个槽：比特值为1，则该比特对应的槽在节点中；比特值为0，则该比特对应的槽不在节点中
    unsigned char slots[16384/8];
 
    //节点中槽的数量
    int numslots;
 
    …………
 
} clusterNode;
```

​		**clusterState数据结构：**

```c
typedef struct clusterState {
 
    //自身节点
    clusterNode *myself;
 
    //配置纪元
    uint64_t currentEpoch;
 
    //集群状态：在线还是下线
    int state;
 
    //集群中至少包含一个槽的节点数量
    int size;
 
    //哈希表，节点名称->clusterNode节点指针
    dict *nodes;
  
    //槽分布信息：数组的每个元素都是一个指向clusterNode结构的指针；如果槽还没有分配给任何节点，则为NULL
    clusterNode *slots[16384];
 
    …………
     
} clusterState;
```

### 4）简述集群命令的实现

​		以cluster meet(节点握手)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。假设要向A节点发送cluster meet命令，将B节点加入到A所在的集群，则A节点收到命令后，执行的操作如下：

-1-  A为B创建一个clusterNode结构，并将其添加到clusterState的nodes字典中

-2-  A向B发送MEET消息

-3-  B收到MEET消息后，会为A创建一个clusterNode结构，并将其添加到clusterState的nodes字典中

-4-  B回复A一个PONG消息

-5-  A收到B的PONG消息后，便知道B已经成功接收自己的MEET消息

-6-  然后，A向B返回一个PING消息

-7-  B收到A的PING消息后，便知道A已经成功接收自己的PONG消息，握手完成

-8-  之后，A通过Gossip协议将B的信息广播给集群内其他节点，其他节点也会与B握手；一段时间后，集群收敛，B成为集群内的一个普通节点

​		通过上述过程可以发现，**集群中两个节点的握手过程与TCP类似，都是三次握手**：A向B发送MEET；B向A发送PONG；A向B发送PING。

## （4）客户端访问集群

```
	由于集群模式下，数据是分区存储的，数据分布在不同的节点中，若客户端通过某节点访问数据时，数据可能不在该节点中，那集群是如何处理这个问题的？
```

​		当节点收到redis-cli发来的命令(如set/get)时，过程如下：

​		**-1-**  计算key属于哪个槽：CRC16(key) & 16383

​		集群提供的cluster keyslot命令也是使用上述公式实现：
![计算哈希值](\pic\计算哈希值.PNG)

​		**-2-**  判断key所在的槽是否在当前节点：
​		假设key位于第i个槽，clusterState.slots[i]则指向了槽所在的节点，如果clusterState.slots[i]==clusterState.myself，说明槽在当前节点，可以直接在当前节点执行命令；否则，说明槽不在当前节点，则查询槽所在节点的地址(clusterState.slots[i].ip/port)，并将其包装到MOVED错误中返回给redis-cli。

​		**-3-**  redis-cli收到MOVED错误后，根据返回的ip和port重新发送请求。

## （5）实践要点

### 1）集群伸缩

​		实践中常常需要对集群进行伸缩，如访问量增大时的扩容操作。Redis集群可以在不影响对外服务的情况下实现伸缩；**伸缩的核心是槽迁移：修改槽与节点的对应关系，实现槽(即数据)在节点之间的移动**。例如，如果槽均匀分布在集群的3个节点中，此时增加一个节点，则需要从3个节点中分别拿出一部分槽给新节点，从而实现槽在4个节点中的均匀分布。

​		**-1-  增加节点**

​		假设要增加7003和8003节点，其中8003是7003的从节点；步骤如下：

（1）启动节点：方法参见集群搭建

（2）节点握手：可以使用cluster meet命令，但在生产环境中建议使用redis-trib.rb的add-node工具，其原理也是cluster meet，但它会先检查新节点是否已加入其它集群或者存在数据，避免加入到集群后带来混乱。

```c
redis-trib.rb add-node 192.168.72.128:7003 192.168.72.128 7000
redis-trib.rb add-node 192.168.72.128:8003 192.168.72.128 7000
```

（3）迁移槽：推荐使用redis-trib.rb的reshard工具实现。reshard自动化程度很高，只需要输入redis-trib.rb reshard ip:port (ip和port可以是集群中的任一节点)，然后按照提示输入以下信息，槽迁移会自动完成：

- - 待迁移的槽数量：16384个槽均分给4个节点，每个节点4096个槽，因此待迁移槽数量为4096
  - 目标节点id：7003节点的id
  - 源节点的id：7000/7001/7002节点的id

（4）指定主从关系：方法参见集群搭建

​		**-2-  减少节点**

​		假设要下线7000/8000节点，可以分为两步：

（1）迁移槽：使用reshard将7000节点中的槽均匀迁移到7001/7002/7003节点

（2）下线节点：使用redis-trib.rb del-node工具；应先下线从节点再下线主节点，因为若主节点先下线，从节点会被指向其他主节点，造成不必要的全量复制。

```c
redis-trib.rb del-node 192.168.72.128:7001 {节点8000的id}
redis-trib.rb del-node 192.168.72.128:7001 {节点7000的id}
```

### 2）故障转移

​		集群的故障转移实现与哨兵思路类似：通过定时任务发送PING消息检测其他节点状态；节点下线分为主观下线和客观下线；客观下线后选取从节点进行故障转移。
​		与哨兵一样，集群只实现了主节点的故障转移；从节点故障时只会被下线，不会进行故障转移。因此，使用集群时，应谨慎使用读写分离技术，因为从节点故障会导致读服务不可用，可用性变差。
这里不再详细介绍故障转移的细节，只对重要事项进行说明：

**节点数量：**在故障转移阶段，需要由主节点投票选出哪个从节点成为新的主节点；从节点选举胜出需要的票数为N/2+1；其中N为主节点数量(包括故障主节点)，但故障主节点实际上不能投票。因此为了能够在故障发生时顺利选出从节点，集群中至少需要3个主节点(且部署在不同的物理机上)。

**故障转移时间：**从主节点故障发生到完成转移，所需要的时间主要消耗在主观下线识别、主观下线传播、选举延迟等几个环节；具体时间与参数cluster-node-timeout有关，一般来说：
		故障转移时间(毫秒) ≤ 1.5 * cluster-node-timeout + 1000
		cluster-node-timeout的默认值为15000ms(15s)，因此**故障转移时间会在20s量级**。

### 3）Hash Tag

​		Hash Tag原理是：**当一个key包含 {}的时候，不对整个key做hash，而仅对 {}包括的字符串做hash**。Hash Tag可以让不同的key拥有相同的hash值，从而分配在同一个槽里；这样针对不同key的批量操作(mget/mset等)，以及事务、Lua脚本等都可以支持。
​		不过Hash Tag可能会带来数据分配不均的问题，这时需要：a. 调整不同节点中槽的数量，使数据分布尽量均匀；b. 避免对热点数据使用Hash Tag，导致请求分布不均。

### 4）redis-trib.rb

​		redis-trib.rb提供了众多实用工具：创建集群、增减节点、槽迁移、检查完整性、数据重新平衡等。通过help命令可以查看详细信息。在实践中如果能使用redis-trib.rb工具则尽量使用，不但方便快捷，还可以大大降低出错概率。

